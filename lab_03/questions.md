# Контрольные вопросы

## Задача регрессии
**Задача регрессии** состоит в том, чтобы предсказать числовое значение выходной переменной (целевой переменной) на основе входных данных. Регрессия используется, когда необходимо установить зависимость между одной или несколькими независимыми переменными (признаками) и целевой переменной.

### Примеры задач регрессии:
1. Предсказание цены недвижимости на основе площади, расположения, возраста дома.
2. Оценка уровня загрязнения воздуха на основе погодных данных, времени суток и трафика.
3. Прогнозирование продаж магазина по данным о прошлых продажах, рекламе и сезонности.
4. Предсказание расхода топлива автомобиля на основе скорости, веса и типа двигателя.

---

## Что такое метод градиентного спуска?
**Метод градиентного спуска** — это алгоритм оптимизации, используемый для минимизации функции ошибки. Он работает за счет итеративного обновления параметров модели в направлении, противоположном градиенту функции ошибки. Этот процесс помогает находить минимум функции ошибки, улучшая качество модели.

### Принцип работы:
1. Вычислить градиент функции ошибки по параметрам модели.
2. Обновить параметры модели: 
   \[
   \theta = \theta - \alpha \cdot \nabla J(\theta),
   \]
   где:
   - \( \theta \) — параметры модели,
   - \( \alpha \) — скорость обучения,
   - \( \nabla J(\theta) \) — градиент функции ошибки.

---

## Что такое скорость обучения в методе градиентного спуска?
**Скорость обучения (learning rate)** — это гиперпараметр, определяющий размер шага, на который обновляются параметры модели на каждом этапе оптимизации. 

- **Малое значение скорости обучения** приводит к медленному обучению, увеличивая время нахождения минимума.
- **Большое значение скорости обучения** может сделать процесс нестабильным, приводя к колебаниям или невозможности сходимости.

---

## Какие функции ошибки используются в регрессионных моделях и почему?
Основные функции ошибки, используемые в регрессии:
1. **Среднеквадратическая ошибка (Mean Squared Error, MSE)**:
   \[
   MSE = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2
   \]
   - Используется из-за того, что она увеличивает вес крупных ошибок, что помогает модели минимизировать их.
   
2. **Средняя абсолютная ошибка (Mean Absolute Error, MAE)**:
   \[
   MAE = \frac{1}{n} \sum_{i=1}^n |y_i - \hat{y}_i|
   \]
   - Более устойчива к выбросам, так как одинаково учитывает ошибки разной величины.

3. **Хюберовская ошибка (Huber Loss)**:
   - Комбинирует преимущества MSE и MAE, игнорируя большие выбросы и учитывая меньшие ошибки.

4. **RMSLE (Root Mean Squared Logarithmic Error)**:
   - Удобна, если важна относительная ошибка, а не абсолютная.

Эти функции ошибки выбираются в зависимости от задачи и распределения ошибок.

---

## Что показывает конкретное значение ошибки регрессии?
Значение ошибки регрессии показывает, насколько предсказания модели отличаются от фактических значений целевой переменной. 

- **Низкое значение ошибки** говорит о том, что модель делает точные предсказания.
- **Высокое значение ошибки** указывает на необходимость доработки модели или изменения признаков.

---

## Что показывает график обучения и зачем его строить?
**График обучения** показывает изменение значения функции ошибки (например, MSE или MAE) на обучающей и валидационной выборках в зависимости от итерации или эпохи.

### Зачем его строить:
1. **Диагностика переобучения:** Если ошибка на обучающей выборке уменьшается, а на валидационной растет, это указывает на переобучение.
2. **Диагностика недообучения:** Если ошибка на обеих выборках остается высокой, модель недообучена.
3. **Подбор параметров:** График помогает определить оптимальное количество итераций или эпох.

График позволяет визуализировать процесс обучения и принимать обоснованные решения по улучшению модели.