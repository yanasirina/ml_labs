### Контрольные вопросы

#### 1. В чем заключается суть метода множественной регрессии?
Метод множественной регрессии используется для моделирования зависимости между одной зависимой переменной (целевой) и несколькими независимыми переменными (факторами). Основная цель — определить, как каждая независимая переменная влияет на целевую переменную, а также сделать прогнозы на основе модели.

#### 2. Какие основные недостатки применения полиномиальных признаков на практике?
- **Переобучение:** При слишком высокой степени полинома модель может слишком точно подстраиваться под обучающую выборку, теряя обобщающую способность.
- **Рост вычислительных затрат:** С увеличением степени полинома значительно растет число признаков, что увеличивает объем вычислений.
- **Сложность интерпретации:** Модель становится менее интерпретируемой, так как коэффициенты при полиномиальных признаках трудно связать с исходными данными.

#### 3. В каких случаях введение полиномиальных признаков может быть полезным?
- Когда данные имеют выраженную нелинейную зависимость, и линейная модель не может адекватно описать их структуру.
- Если имеется небольшое количество признаков, и использование полиномов не приведет к значительному увеличению размерности пространства.

#### 4. Как растет требование к объему оперативной памяти при введении полиномиальных признаков?
Требования к памяти растут экспоненциально с увеличением степени полинома и количества признаков, так как число новых признаков определяется комбинаторикой. Например, для \( n \) исходных признаков и степени \( d \) число новых признаков будет равно \( \frac{(n + d)!}{n! \cdot d!} \).

#### 5. Почему при введении полиномиальных признаков нужно добавить все комбинации атрибутов до заданной степени?
Включение всех комбинаций атрибутов до заданной степени позволяет модели учитывать взаимодействия между признаками на различных уровнях. Пропуск некоторых комбинаций может привести к потере информации о потенциально важных взаимодействиях.

#### 6. Почему на последнем графике линия получается прямая, хотя мы используем нелинейную модель?
Прямая линия может получаться из-за следующих причин:
- Модель была обучена на преобразованных признаках, но итоговый график строится в исходных координатах.
- Нелинейность модели проявляется в высокомерных измерениях, но ее проекция на рассматриваемое пространство остается линейной.
- Модель переобучена, и оптимизация веса приводит к "выпрямлению" выходной зависимости.
